{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": "preprocessing zmiennych:"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def preprocess_clean_data(dane: pd.DataFrame, y_col: str):\n",
    "    dane = dane.rename(columns={\"#Layovers\": \"Num_Layovers\", \"Price [PLN]\": \"Price\"})\n",
    "\n",
    "    # Przekszta≈Çcenie dat\n",
    "    if \"Flight_date\" in dane.columns:\n",
    "        dane[\"Flight_date\"] = pd.to_datetime(dane[\"Flight_date\"], errors=\"coerce\")\n",
    "    if \"Extraction_Time\" in dane.columns:\n",
    "        dane[\"Extraction_Time\"] = pd.to_datetime(\n",
    "            dane[\"Extraction_Time\"].str.split(\" \").apply(lambda x: x[0]),\n",
    "            dayfirst=True, errors=\"coerce\"\n",
    "        )\n",
    "    dane[\"Ticket_class\"] = dane[\"Ticket_class\"].map({\"Ekonomiczna\": 0, \"Biznes\": 1})\n",
    "    # Usuniƒôcie zbƒôdnych kolumn\n",
    "    kolumny_do_usuniecia = [\n",
    "        \"Extraction_Time\", \"Flight_date\", \"arr_city\", \"dep_city\",\n",
    "        \"Departure_airport_name\", \"Destination_airport_name\",\n",
    "        \"layover_airport\", \"ujemne\", \"low_cost1\", \"low_cost2\",\n",
    "        \"Departure_airport_code\", \"Destination_airport_code\",\n",
    "        \"Flight_weekday\", \"Extraction_Weekday\",\n",
    "        \"Airline1\",\"Airline2\",\"Is_-2\"\n",
    "    ]\n",
    "    dane.drop(columns=kolumny_do_usuniecia, inplace=True, errors='ignore')\n",
    "\n",
    "    # Oddzielenie celu od cech\n",
    "    y = dane[y_col].copy()\n",
    "    X = dane.drop(columns=[y_col])\n",
    "\n",
    "    # Konwersja kolumn tekstowych do liczb, je≈õli trzeba\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == 'object':\n",
    "            X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "    # Uzupe≈Çnianie brak√≥w\n",
    "    X.fillna(0, inplace=True)\n",
    "    y.fillna(y.mean(), inplace=True)\n",
    "\n",
    "    return X, y\n"
   ],
   "id": "ab6fe46c19bd11c2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Analiza klasyfikacji w zale≈ºnosci od usunietej kolumny\n",
   "id": "28196e06d5b20e54"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from perceptron_nn_classifier import MultiLayerPerceptronClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from glob import glob\n",
    "\n",
    "# === Parametry eksperymentu ===\n",
    "num_repetitions = 5\n",
    "target_col = \"Price\"  # zak≈Çadamy ≈ºe to teraz kategoria/klasa\n",
    "\n",
    "# === Wczytanie i wstƒôpne przetworzenie danych ===\n",
    "df = pd.read_excel(\"loty_clean.xlsx\")\n",
    "X_full, y_full = preprocess_clean_data(df.copy(), y_col=target_col)\n",
    "\n",
    "# Je≈õli y_full nie jest zakodowane do one-hot\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "y_full_encoded = lb.fit_transform(y_full)\n",
    "num_classes = len(lb.classes_)\n",
    "\n",
    "# Lista kolumn do testowania (po preprocessingu)\n",
    "testable_columns = X_full.columns.tolist()\n",
    "\n",
    "# Parametry sieci (bazowe)\n",
    "baseline_params = {\n",
    "    \"num_layers\": [15],\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"activation_function\": \"relu\",\n",
    "    \"num_epochs\": 2000\n",
    "}\n",
    "\n",
    "# Lista wynik√≥w\n",
    "results = []\n",
    "\n",
    "# === Pƒôtla po kolumnach ===\n",
    "for col in testable_columns:\n",
    "    print(f\"\\nüß™ Testujƒô bez kolumny: {col}\")\n",
    "\n",
    "    X_temp = X_full.drop(columns=[col])\n",
    "\n",
    "    try:\n",
    "        # Podzia≈Ç na train/val/test\n",
    "        X_train_np, X_temp_np, y_train_np, y_temp_np = train_test_split(X_temp, y_full_encoded, test_size=0.3, random_state=42)\n",
    "        X_val_np, X_test_np, y_val_np, y_test_np = train_test_split(X_temp_np, y_temp_np, test_size=0.5, random_state=42)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå B≈ÇƒÖd przy podziale danych (kolumna {col}): {e}\")\n",
    "        continue\n",
    "\n",
    "    # Miejsce na metryki z powt√≥rze≈Ñ\n",
    "    acc_list, prec_list, rec_list, f1_list = [], [], [], []\n",
    "\n",
    "    for i in range(num_repetitions):\n",
    "        print(f\"   üîÅ Powt√≥rzenie {i+1}/{num_repetitions}\")\n",
    "        try:\n",
    "            mlp = MultiLayerPerceptronClassifier(\n",
    "                num_inputs=X_train_np.shape[1],\n",
    "                num_classes=num_classes,\n",
    "                num_layers=baseline_params[\"num_layers\"],\n",
    "                learning_rate=baseline_params[\"learning_rate\"],\n",
    "                activation_function=baseline_params[\"activation_function\"]\n",
    "            )\n",
    "\n",
    "            mlp.fit(\n",
    "                X=X_train_np,\n",
    "                y=y_train_np,\n",
    "                X_val=X_val_np,\n",
    "                y_val=y_val_np,\n",
    "                num_epochs=baseline_params[\"num_epochs\"],\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "            y_pred = mlp.predict(X_test_np)\n",
    "            y_true = np.argmax(y_test_np, axis=1)\n",
    "\n",
    "            acc_list.append(accuracy_score(y_true, y_pred))\n",
    "            prec_list.append(precision_score(y_true, y_pred, average=\"weighted\", zero_division=0))\n",
    "            rec_list.append(recall_score(y_true, y_pred, average=\"weighted\", zero_division=0))\n",
    "            f1_list.append(f1_score(y_true, y_pred, average=\"weighted\", zero_division=0))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå B≈ÇƒÖd treningu dla kolumny {col}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Zapisz ≈õrednie wyniki dla danej kolumny\n",
    "    results.append({\n",
    "        \"usuniƒôta_kolumna\": col,\n",
    "        \"test_accuracy\": np.mean(acc_list),\n",
    "        \"test_precision\": np.mean(prec_list),\n",
    "        \"test_recall\": np.mean(rec_list),\n",
    "        \"test_f1\": np.mean(f1_list)\n",
    "    })\n",
    "\n",
    "# === Zapis wynik√≥w ===\n",
    "results_df = pd.DataFrame(results)\n",
    "filename = f\"dobor_zmiennych_klasyfikacja_nn_{len(glob('dobor_zmiennych_klasyfikacja_nn_*.xlsx')) + 1}.xlsx\"\n",
    "results_df.to_excel(filename, index=False)\n",
    "print(f\"\\n‚úÖ Wyniki zapisane do pliku: {filename}\")\n"
   ],
   "id": "6db0afbc6aed06f2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
